# Projeto de Data Warehouse e An√°lise de Vendas para a Livraria DevSaber
## Integrantes do Mini projeto
Carol Rocha
Bruna Nascimento
Tamires Melo
Raquel Rios 
![Google BigQuery](https://img.shields.io/badge/Google_BigQuery-4285F4?style=for-the-badge&logo=google-bigquery&logoColor=white)
![SQL](https://img.shields.io/badge/SQL-025E8C?style=for-the-badge&logo=sql&logoColor=white)
![Git](https://img.shields.io/badge/Git-F05032?style=for-the-badge&logo=git&logoColor=white)
![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)

## 1. üéØ Miss√£o do Projeto

Este projeto simula um cen√°rio de consultoria real onde a livraria "DevSaber" buscou escalar sua an√°lise de dados. A miss√£o foi migrar o controle de vendas de planilhas fr√°geis para um mini Data Warehouse robusto no Google BigQuery, construindo um pipeline de dados completo: da modelagem e cria√ß√£o das tabelas √† ingest√£o e, finalmente, √† extra√ß√£o de insights estrat√©gicos atrav√©s de consultas SQL e Views.

## 2. üìñ O Desafio: Do Caos da Planilha √† Intelig√™ncia de Neg√≥cios

Toda empresa em crescimento enfrenta um ponto de inflex√£o onde planilhas se tornam um gargalo. A Livraria DevSaber estava nesse ponto, enfrentando desafios como:
-   **Falta de Escalabilidade:** Dificuldade para lidar com um volume crescente de vendas.
-   **Risco √† Integridade dos Dados:** Erros manuais e falta de padroniza√ß√£o.
-   **Incapacidade Anal√≠tica:** Impossibilidade de realizar an√°lises complexas e cruzar informa√ß√µes de forma eficiente.

Este projeto resolve esses problemas, criando uma funda√ß√£o de dados s√≥lida para o futuro da empresa.

## 3. üõ†Ô∏è Ferramentas e Conceitos Aplicados

* **Cloud:** Google BigQuery como plataforma de Data Warehouse.
* **Linguagem:** SQL para todas as etapas do projeto (DDL, DML).
* **Conceitos de BigQuery:**
    * Tipos de dados otimizados (`STRING`, `INT64`).
    * Paradigma sem chaves (PK/FK), com relacionamentos l√≥gicos via `JOIN`.
    * Uso de `CREATE OR REPLACE` para scripts idempotentes.
* **Pipeline de Dados (ETL):**
    * **Extract:** Dados extra√≠dos de uma "planilha" conceitual.
    * **Transform:** Modelagem dos dados em um schema relacional (Clientes, Produtos, Vendas).
    * **Load:** Ingest√£o dos dados com `INSERT INTO`.
* **An√°lise de Dados:** `SELECT`, `JOIN` para cruzar informa√ß√µes e `SUM/GROUP BY` para agrega√ß√£o.
* **Automa√ß√£o e Reuso:** Cria√ß√£o de `VIEW` para simplificar o acesso a consultas complexas.

## 4. üöÄ O Pipeline de Dados: Passo a Passo da Execu√ß√£o

O projeto foi estruturado em um pipeline claro e sequencial. Todos os scripts est√£o organizados na pasta `/sql/`.

### Etapa 1: Construindo a Funda√ß√£o (DDL - `CREATE TABLE`)

O primeiro passo foi modelar e criar as tabelas que serviriam como a "casa" dos dados. Foram criadas 3 tabelas normalizadas: `Clientes`, `Produtos` e `Vendas`. A l√≥gica de n√£o usar chaves prim√°rias/estrangeiras segue o paradigma de performance do BigQuery.

* [Ver script de cria√ß√£o da tabela `Clientes`](sql/1_criacao_tabelas/01_create_clientes.sql)
* [Ver script de cria√ß√£o da tabela `Produtos`](sql/1_criacao_tabelas/02_create_produtos.sql)
* [Ver script de cria√ß√£o da tabela `Vendas`](sql/1_criacao_tabelas/03_create_vendas.sql)

### Etapa 2: Povoando o Data Warehouse (DML - `INSERT INTO`)

Com a estrutura de tabelas pronta, a pr√≥xima fase foi a ingest√£o dos dados. Para este projeto, o comando `INSERT INTO` foi utilizado para carregar os registros iniciais de forma controlada e did√°tica. Em um cen√°rio de produ√ß√£o com maior volume, essa etapa seria automatizada atrav√©s de um pipeline de dados mais robusto (utilizando ferramentas como Cloud Functions, Dataflow, etc.).

Os dados foram inseridos seguindo a ordem de depend√™ncia para garantir a integridade l√≥gica:
1.  Primeiro, os `Clientes` e `Produtos`.
2.  Por √∫ltimo, as `Vendas`, que conectam as duas tabelas anteriores.

* [Ver exemplos de scripts de ingest√£o de dados](/sql/2_ingestao_dados/)

### Etapa 3: Extraindo Insights (An√°lise com `SELECT`)

Esta √© a etapa onde o valor √© gerado. A consulta abaixo unifica os dados das tr√™s tabelas para criar um relat√≥rio detalhado de vendas, respondendo √† principal pergunta de neg√≥cio.

**Pergunta: Listar todas as vendas com detalhes do cliente e do produto.**
```sql
SELECT
    C.Nome_Cliente,
    P.Nome_Produto,
    V.Data_Venda
FROM `seu-projeto.LivrariaDevSaber_t3_15.Vendas` AS V
JOIN `seu-projeto.LivrariaDevSaber_t3_15.Clientes` AS C ON V.ID_Cliente = C.ID_Cliente
JOIN `seu-projeto.LivrariaDevSaber_t3_15.Produtos` AS P ON V.ID_Produto = P.ID_Produto
ORDER BY V.Data_Venda;
```

### Etapa 4: Automatizando An√°lises com `CREATE VIEW`

Uma vez que a principal consulta anal√≠tica foi definida, o passo final foi criar uma camada de abstra√ß√£o para simplificar o acesso futuro a esses dados. Reescrever `JOIN`s complexos diariamente √© ineficiente e aumenta a chance de erros.

A solu√ß√£o foi encapsular toda a l√≥gica em uma **`VIEW`**. Uma `VIEW` funciona como uma "tabela virtual" que armazena uma consulta, permitindo que qualquer pessoa no time possa acessar os dados j√° processados de forma simples e segura.


**C√≥digo de Cria√ß√£o da View `v_relatorio_vendas_detalhado`:**

```sql
CREATE OR REPLACE VIEW `seu-projeto.LivrariaDevSaber_t3_15.v_relatorio_vendas_detalhado` AS
SELECT
    V.ID_Venda,
    V.Data_Venda,
    C.Nome_Cliente,
    P.Nome_Produto,
    V.Quantidade,
    (V.Quantidade * P.Preco_Produto) AS Valor_Total
FROM `seu-projeto.LivrariaDevSaber_t3_15.Vendas` AS V
JOIN `seu-projeto.LivrariaDevSaber_t3_15.Clientes` AS C ON V.ID_Cliente = C.ID_Cliente
JOIN `seu-projeto.LivrariaDevSaber_t3_15.Produtos` AS P ON V.ID_Produto = P.ID_Produto;
```

Benef√≠cio na Pr√°tica
Com a VIEW criada, a equipe da "Livraria DevSaber" n√£o precisa mais se preocupar com a complexidade dos JOINs. Para ver as vendas de um cliente espec√≠fico, a consulta se torna trivial:

```sql
SELECT *
FROM `seu-projeto.LivrariaDevSaber_t3_15.v_relatorio_vendas_detalhado`
WHERE Nome_Cliente = 'Ana Silva';
```